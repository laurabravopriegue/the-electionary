# -*- coding: utf-8 -*-
from __future__ import division
import urllib
from string import punctuation
from operator import itemgetter
from string import digits
from collections import Counter 
import operator
import nltk
wnl = nltk.WordNetLemmatizer()
from nltk.probability import FreqDist

#This is just a sentiment analysis of the Trump-Hillary presidential debates 

class color:
   UNDERLINE = '\033[4m'
   END = '\033[0m'

#read text and create a list

#clinton
clintonone = open("/Users/laurabravopriegue/transcript-processing/Debate-one-Clinton.txt").read()
clintontwo = open("/Users/laurabravopriegue/transcript-processing/Debate-two-Clinton.txt").read()
clintonthree = open("/Users/laurabravopriegue/transcript-processing/Debate-three-Clinton.txt").read()

clinton = " " 
clinton = clintonone + clintontwo + clintonthree


#trump
trumpone = open("/Users/laurabravopriegue/transcript-processing/Debate-one-Trump.txt").read()
trumptwo = open("/Users/laurabravopriegue/transcript-processing/Debate-two-Trump.txt").read()
trumpthree = open("/Users/laurabravopriegue/transcript-processing/Debate-three-Trump.txt").read()

trump = " " 
trump = trumpone + trumptwo + trumpthree

#split the text into words
#remove capital letters, numbers and punctuation

clinton = clinton.lower()
trump = trump.lower()

for p in list(punctuation):
        clinton=clinton.replace(p,'')
        trump=trump.replace(p,'')
        
for k in list(digits):
        clinton=clinton.replace(k,'')
        trump=trump.replace(k,'')
        
clinton_words = clinton.split()
trump_words = trump.split()

long_words = [w for w in clinton_words if len(w) > 3]
long_wordstrump = [w for w in trump_words if len(w) > 3]
    
clinton_words = [wnl.lemmatize(t) for t in long_words]
trump_words = [wnl.lemmatize(t) for t in long_wordstrump]

clinton_words_tagged = nltk.pos_tag(clinton_words)
trump_words_tagged = nltk.pos_tag(trump_words)

clinton_nouns = " " 
trump_nouns = " " 

for word,pos in clinton_words_tagged:
    if (pos == 'NN' or pos == 'NNP'):
        clinton_nouns += (" " + word)
        
for word,pos in trump_words_tagged:
    if (pos == 'NN' or pos == 'NNP'):
        trump_nouns += (" " + word)

clinton_nouns = clinton_nouns.split()
trump_nouns = trump_nouns.split()

print color.UNDERLINE + '' + color.END
  
#total number of words     
clinton_word_count=len(clinton_nouns) 
trump_word_count=len(trump_nouns)

print color.UNDERLINE + 'Total number of words' + color.END
print "Clinton: " 
print clinton_word_count
print "Trump: " 
print trump_word_count

print '  ' 

#import positive and negative lists
#create counters for both 

files=['negative.txt','positive.txt']

path='http://www.unc.edu/~ncaren/haphazard/'
for file_name in files:
    urllib.urlretrieve(path+file_name,file_name)
    
pos_words = open("positive.txt").read()
positive_words=pos_words.split('\n')
positive_counts=[]

neg_words = open('negative.txt').read()
negative_words=neg_words.split('\n')
negative_counts=[]

for k in clinton_nouns:
    positive_counter=0
    negative_counter=0
    
for k in trump_nouns:
    pos_counter=0
    neg_counter=0

print '  ' 

#count positive and negative words
print color.UNDERLINE + 'Positive words in the text' + color.END

print "Clinton:"
for word in clinton_nouns:
    if word in positive_words:
        positive_counter=positive_counter+1
        print word
        
print "Trump:"
for word in trump_nouns:
    if word in positive_words:
        pos_counter=pos_counter+1
        print word
        
print '  ' 

print color.UNDERLINE + 'Negative words in the text' + color.END

print "Clinton:"
for word in clinton_nouns:
    if word in negative_words:
        negative_counter=negative_counter+1
        print word
        
print "Trump:"
for word in trump_nouns:
    if word in negative_words:
        neg_counter=neg_counter+1
        print word
        
print '  ' 

print color.UNDERLINE + 'Total number of positive words' + color.END
print "Clinon:" 
print positive_counter 
print "Trump: " 
print pos_counter 

print color.UNDERLINE + 'Total number of negative words' + color.END
print "Clinton: " 
print negative_counter 
print "Trump: " 
print neg_counter 

print '  ' 

#percentage of positive and negative words

print color.UNDERLINE + 'Percentage of words that are positive' + color.END
print "Clinton: " 
print positive_counter/clinton_word_count
print "Trump: " 
print pos_counter/trump_word_count

print color.UNDERLINE + 'Percentage of words that are negative' + color.END
print "Clinton: " 
print negative_counter/clinton_word_count
print "Trump: " 
print neg_counter/trump_word_count

#50 most frequent words

print '  ' 

print color.UNDERLINE + '70 most frequent words:' + color.END


print "Clinton:" 
word_counter = {}
for word in clinton_nouns:
    if len(word) > 0 and word != '\r\n':
        if word not in word_counter: # if 'word' not in word_counter, add it, and set value to 1
            word_counter[word] = 1
        else:
            word_counter[word] += 1 # if 'word' already in word_counter, increment it by 1

for i,word in enumerate(sorted(word_counter,key=word_counter.get,reverse=True)[:50
]):
    # sorts the dict by the values, from top to botton, takes the 70 top items,
    print "%s: %s - %s"%(i+1,word,word_counter[word])
    
print "Trump:" 
word_counter_trump = {}
for word in trump_nouns:
    if word not in word_counter_trump: # if 'word' not in word_counter, add it, and set value to 1
        word_counter_trump[word] = 1
    else:
        word_counter_trump[word] += 1 # if 'word' already in word_counter, increment it by 1

for i,word in enumerate(sorted(word_counter_trump,key=word_counter_trump.get,reverse=True)[:50]):
    # sorts the dict by the values, from top to botton, takes the 70 top items,
    print "%s: %s - %s"%(i+1,word,word_counter_trump[word])


#Create cumulative frequency graph for the 50 more frequent words 

textclinton = nltk.Text(clinton_nouns)
fdist1 = FreqDist(textclinton)
fdist1.plot(50, cumulative=True, color='blue')
    
texttrump = nltk.Text(trump_nouns)
fdist2 = FreqDist(texttrump)
fdist2.plot(50, cumulative=True, color='red')     
 
 
#Words that appear together in the text 

print "Collocations Clinton:"
textclinton1 = nltk.Text(clinton_words)
textclinton1.collocations()

print "Collocations Trump:"
texttrump1 = nltk.Text(trump_words)
texttrump1.collocations()
